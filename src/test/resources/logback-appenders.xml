<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE logback>
<included>

  <appender name="CLOUDWATCH_SYNC"
    class="ch.qos.logback.more.appenders.CloudWatchLogbackAppender">

    <awsConfig>
      <!-- [Optional] Place AwsCredentials.properties in class path. -->
      <credentialFilePath>AwsCredentials.properties</credentialFilePath>
      <region>ap-northeast-1</region>
    </awsConfig>
    <logGroupName>test-log</logGroupName>
    <!-- [Optional] Automatically roll current log stream and resume logging in a new stream. -->
    <logStreamRolling class="ch.qos.logback.more.appenders.CountBasedStreamName">
      <!-- The limit is not exactly checked. The stream can have more than the limit depends on emitInterval and maxFlushTime. -->
      <limit>100000</limit>
    </logStreamRolling>
    <!-- [Optional] Or you can specify static stream name.
    <logStreamName>my-log-stream</logStreamName>
    -->
    <!-- [Optional] Create Log group and stream automatically. -->
    <createLogDestination>true</createLogDestination>
    <!-- The minimum interval millis for each CloudWatch API call. -->
    <emitInterval>100</emitInterval>

    <encoder>
      <pattern><![CDATA[[%thread] %-5level %logger{15}#%line %msg]]></pattern>
    </encoder>
  </appender>

  <appender name="CLOUDWATCH" class="ch.qos.logback.classic.AsyncAppender">
    <!-- Max queue size of logs which is waiting to be sent (When it reach to the max size, the log will be disappeared). -->
    <queueSize>999</queueSize>
    <!-- Never block when the queue becomes full. -->
    <neverBlock>true</neverBlock>
    <!-- The default maximum queue flush time allowed during appender stop. 
         If the worker takes longer than this time it will exit, discarding any remaining items in the queue.
         10000 millis
     -->
   <maxFlushTime>100</maxFlushTime>
    <appender-ref ref="CLOUDWATCH_SYNC" />
  </appender>


  <appender name="DYNAMODB_SYNC"
    class="ch.qos.logback.more.appenders.DynamoDBLogbackAppender">

    <awsConfig>
      <!-- [Optional] Place AwsCredentials.properties in class path. -->
      <credentialFilePath>AwsCredentials.properties</credentialFilePath>
      <region>ap-northeast-1</region>
    </awsConfig>

    <!-- Table name of DynamoDB -->
    <outputTableName>AppLog</outputTableName>
    <!-- Unique instance name for this app server instance.
         If you have multiple servers, you need to use different name for each servers. -->
    <instanceName>instance-1</instanceName>

    <encoder>
      <pattern><![CDATA[%date{HH:mm:ss.SSS} [%thread] %-5level %logger{15}#%line %msg]]></pattern>
    </encoder>
  </appender>

  <appender name="DYNAMODB" class="ch.qos.logback.classic.AsyncAppender">
    <!-- Max queue size of logs which is waiting to be sent (When it reach to the max size, the log will be disappeared). -->
    <queueSize>999</queueSize>
    <!-- Never block when the queue becomes full. -->
    <neverBlock>true</neverBlock>
    <!-- The default maximum queue flush time allowed during appender stop. 
         If the worker takes longer than this time it will exit, discarding any remaining items in the queue.
         10000 millis
     -->
    <maxFlushTime>1000</maxFlushTime>
    <appender-ref ref="DYNAMODB_SYNC" />
  </appender>


  <appender name="FLUENT_SYNC"
    class="ch.qos.logback.more.appenders.DataFluentAppender">

    <!-- Tag for Fluentd. Farther information: http://docs.fluentd.org/articles/config-file -->
    <tag>debug</tag>
    <!-- [Optional] Label for Fluentd. Farther information: http://docs.fluentd.org/articles/config-file -->
    <label>logback</label>
    <!-- Host name/address and port number which Flentd placed -->
    <remoteHost>localhost</remoteHost>
    <port>24224</port>
    <!-- [Optional] Additional fields(Pairs of key: value) -->
    <additionalField>
      <key>foo</key>
      <value>bar</value>
    </additionalField>
    <additionalField>
      <key>foo2</key>
      <value>bar2</value>
    </additionalField>
    <!--  [Optional] If true, Map Marker is expanded instead of nesting in the marker name -->
    <flattenMapMarker>false</flattenMapMarker>

    <encoder>
      <pattern><![CDATA[%date{HH:mm:ss.SSS} [%thread] %-5level %logger{15}#%line %msg]]></pattern>
    </encoder>
  </appender>

  <appender name="FLUENT" class="ch.qos.logback.classic.AsyncAppender">
    <!-- Max queue size of logs which is waiting to be sent (When it reach to the max size, the log will be disappeared). -->
    <queueSize>999</queueSize>
    <!-- Never block when the queue becomes full. -->
    <neverBlock>true</neverBlock>
    <!-- The default maximum queue flush time allowed during appender stop. 
         If the worker takes longer than this time it will exit, discarding any remaining items in the queue.
         10000 millis
     -->
    <maxFlushTime>10000</maxFlushTime>
    <appender-ref ref="FLUENT_SYNC" />
  </appender>


  <appender name="FLUENCY_SYNC" class="ch.qos.logback.more.appenders.FluencyLogbackAppender">
    <!-- Tag for Fluentd. Farther information: http://docs.fluentd.org/articles/config-file -->
    <tag>debug</tag>

    <!-- Host name/address and port number which Flentd placed -->
    <remoteHost>localhost</remoteHost>
    <port>24224</port>

    <!-- [Optional] Multiple name/addresses and port numbers which Flentd placed -->
   <remoteServers>
      <remoteServer>
        <host>primary</host>
        <port>24224</port>
      </remoteServer>
      <remoteServer>
        <host>secondary</host>
        <port>24224</port>
      </remoteServer>
    </remoteServers>

    <!-- [Optional] Additional fields(Pairs of key: value) -->
    <additionalField>
      <key>foo</key>
      <value>bar</value>
    </additionalField>
    <additionalField>
      <key>foo2</key>
      <value>bar2</value>
    </additionalField>

    <!-- [Optional] Configurations to customize Fluency's behavior: https://github.com/komamitsu/fluency#usage  -->
    <ackResponseMode>true</ackResponseMode>
    <fileBackupDir>/tmp</fileBackupDir>
    <bufferChunkInitialSize>2097152</bufferChunkInitialSize>
    <bufferChunkRetentionSize>16777216</bufferChunkRetentionSize>
    <maxBufferSize>268435456</maxBufferSize>
    <waitUntilBufferFlushed>30</waitUntilBufferFlushed>
    <waitUntilFlusherTerminated>40</waitUntilFlusherTerminated>
    <flushIntervalMillis>200</flushIntervalMillis>
    <senderMaxRetryCount>12</senderMaxRetryCount>
    <!-- [Optional] Enable/Disable use of EventTime to get sub second resolution of log event date-time -->
    <useEventTime>true</useEventTime>
    <sslEnabled>false</sslEnabled>
    <!--  [Optional] If true, Map Marker is expanded instead of nesting in the marker name -->
    <flattenMapMarker>false</flattenMapMarker>

    <encoder>
      <pattern><![CDATA[%date{HH:mm:ss.SSS} [%thread] %-5level %logger{15}#%line %msg]]></pattern>
    </encoder>
  </appender>

  <appender name="FLUENCY" class="ch.qos.logback.classic.AsyncAppender">
    <!-- Max queue size of logs which is waiting to be sent (When it reach to the max size, the log will be disappeared). -->
    <queueSize>999</queueSize>
    <!-- Never block when the queue becomes full. -->
    <neverBlock>true</neverBlock>
    <!-- The default maximum queue flush time allowed during appender stop. 
         If the worker takes longer than this time it will exit, discarding any remaining items in the queue.
         10000 millis
     -->
    <maxFlushTime>10000</maxFlushTime>
    <appender-ref ref="FLUENCY_SYNC" />
  </appender>


  <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
    <encoder>
      <pattern><![CDATA[%date{HH:mm:ss.SSS} [%thread] %marker %-5level %logger{15}#%line %X{req.requestURI} %msg\n]]></pattern>
    </encoder>
  </appender>

  <appender name="SECURITY_ALERT" class="ch.qos.logback.core.ConsoleAppender">
    <!-- The simple marker filter instead of writing complex configuration with EvaluatorFilter -->
    <filter class="ch.qos.logback.more.appenders.filter.AppendersMarkerFilter">
      <marker>SECURITY_ALERT</marker>
    </filter>

    <target>System.err</target>

    <encoder>
      <pattern><![CDATA[%date{HH:mm:ss.SSS} [%thread] %marker %-5level %logger{15}#%line %X{req.requestURI} %msg\n]]></pattern>
    </encoder>
  </appender>

</included>
